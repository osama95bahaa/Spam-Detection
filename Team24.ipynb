{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmohandes tech\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of transformed training (2314, 53636)\n",
      "shape of transformed testing (579, 53636)\n"
     ]
    }
   ],
   "source": [
    "email = load_files('email',shuffle = True,encoding=\"utf-8\")\n",
    "x = email.data\n",
    "y = email.target\n",
    "x_train ,x_test , y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=101)\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "#fit and transform the training data\n",
    "cv.fit(x_train)\n",
    "transformed_train = cv.transform(x_train)\n",
    "print('shape of transformed training',transformed_train.shape)\n",
    "\n",
    "\n",
    "# transform the testing data\n",
    "transformed_test = cv.transform(x_test)\n",
    "print('shape of transformed testing',transformed_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.481865285 %\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      1.00      1.00       486\n",
      "       spam       0.98      0.99      0.98        93\n",
      "\n",
      "avg / total       0.99      0.99      0.99       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Multinomial NaiveBayes\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "MNB.fit(transformed_train, y_train)\n",
    "predMNB = MNB.predict(transformed_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,predMNB) *100 , '%')\n",
    "print(metrics.classification_report(y_test, predMNB,target_names=email.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.4732297064 %\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      0.96      0.97       486\n",
      "       spam       0.80      0.87      0.84        93\n",
      "\n",
      "avg / total       0.95      0.94      0.95       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#K-neighbours Classifier\n",
    "neigh = KNeighborsClassifier()\n",
    "\n",
    "neigh.fit(transformed_train, y_train)\n",
    "predNeigh = neigh.predict(transformed_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,predNeigh) *100 , '%')\n",
    "print(metrics.classification_report(y_test, predNeigh,target_names=email.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.0639032815 %\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      1.00      0.98       486\n",
      "       spam       1.00      0.82      0.90        93\n",
      "\n",
      "avg / total       0.97      0.97      0.97       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "RFC = RandomForestClassifier(random_state=0)\n",
    "\n",
    "RFC.fit(transformed_train, y_train)\n",
    "predRFC = RFC.predict(transformed_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,predRFC) *100 , '%')\n",
    "print(metrics.classification_report(y_test, predRFC,target_names=email.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2893\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#Features Methods\n",
    "\n",
    "#Word contains a digit\n",
    "def contains_digit(s):\n",
    "    return any(i.isdigit() for i in s)\n",
    "\n",
    "#The number of sentences in an email.\n",
    "def numberSentences(s):\n",
    "    return len(nltk.sent_tokenize(s))\n",
    "\n",
    "#The number of words found in spam list.\n",
    "def numberSpam(s, spam):\n",
    "    count =0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(s)\n",
    "    for w in words:\n",
    "        if w in spam:\n",
    "            count +=1            \n",
    "    return count\n",
    "\n",
    "#The number of words containing numeric characters.\n",
    "def numberNumSentences(s):\n",
    "    numericW =0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(s)\n",
    "    for w in words:\n",
    "        if (contains_digit(w)):\n",
    "            numericW +=1\n",
    "            \n",
    "    return numericW\n",
    "\n",
    "#The number of words containing alphabetical characters.\n",
    "def numberAlphaSentences(s):\n",
    "    AlphaW =0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(s)\n",
    "    for w in words:\n",
    "        if not(contains_digit(w)):\n",
    "            AlphaW +=1            \n",
    "    return AlphaW\n",
    "\n",
    "#The number of words containing both numeric and alphabetical characters. \n",
    "def numberANSentences(s):\n",
    "    count =0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(s)\n",
    "    for w in words:\n",
    "        if re.match('[A-Z0-9]',w):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "#The number of verbs in an email.\n",
    "def numberVerbs(s):\n",
    "    verbs =0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(s)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    for t in tags:\n",
    "        if t[1] == 'VB':\n",
    "            verbs+=1\n",
    "    return verbs\n",
    "\n",
    "#The number of syllables in a word.\n",
    "def sylco(word) :\n",
    " \n",
    "    word = word.lower()\n",
    "    exception_add = ['serious','crucial']\n",
    "    exception_del = ['fortunately','unfortunately']\n",
    "    co_one = ['cool','coach','coat','coal','count','coin','coarse','coup','coif','cook','coign','coiffe','coof','court']\n",
    "    co_two = ['coapt','coed','coinci']\n",
    "    pre_one = ['preach'] \n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number \n",
    "\n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    "  \n",
    "    if word[-2:] == \"es\" or word[-2:] == \"ed\" :\n",
    "        doubleAndtripple_1 = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "        if doubleAndtripple_1 > 1 or len(re.findall(r'[eaoui][^eaoui]',word)) > 1 :\n",
    "            if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "            else :\n",
    "                disc+=1\n",
    "\n",
    "    le_except = ['whole','mobile','pole','male','female','hale','pale','tale','sale','aisle','whale','while']\n",
    " \n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\" and word not in le_except :\n",
    "            pass\n",
    " \n",
    "        else :\n",
    "            disc+=1\n",
    "\n",
    "    doubleAndtripple = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "    tripple = len(re.findall(r'[eaoui][eaoui][eaoui]',word))\n",
    "    disc+=doubleAndtripple + tripple\n",
    " \n",
    "    numVowels = len(re.findall(r'[eaoui]',word))\n",
    " \n",
    "    if word[:2] == \"mc\" :\n",
    "        syls+=1\n",
    " \n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    " \n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "  \n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    " \n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    "  \n",
    "    if word[-3:] == \"ian\" : \n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "  \n",
    "    if word[:2] == \"co\" and word[2] in 'eaoui' :\n",
    " \n",
    "        if word[:4] in co_two or word[:5] in co_two or word[:6] in co_two :\n",
    "            syls+=1\n",
    "        elif word[:4] in co_one or word[:5] in co_one or word[:6] in co_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "  \n",
    "    if word[:3] == \"pre\" and word[3] in 'eaoui' :\n",
    "        if word[:6] in pre_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1 \n",
    "    negative = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\",\"wouldn't\"]\n",
    " \n",
    "    if word[-3:] == \"n't\" :\n",
    "        if word in negative :\n",
    "            syls+=1\n",
    "        else :\n",
    "            pass  \n",
    "\n",
    "    return numVowels - disc + syls\n",
    "\n",
    "#The number of words in an email that have more than 3 syllables. \n",
    "def moreThanThree(s):\n",
    "    count =0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(s)\n",
    "    for w in words:\n",
    "        if sylco(w) >3:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "#The average number of syllables of words in an email. \n",
    "def averageSyllables(s):\n",
    "    syllables =0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(s)\n",
    "    for w in words:\n",
    "            syllables+= sylco(w)\n",
    "    return syllables/len(words)\n",
    "\n",
    "\n",
    "with open('spam.txt') as f:\n",
    "    spam = f.read().splitlines()\n",
    "        \n",
    "#print(spam)\n",
    "\n",
    "f1 = [numberSentences(e) for e in x] # number of sentences of a document.\n",
    "f2 = [numberVerbs(e) for e in x] # The number of verbs in an email.\n",
    "f3 = [numberANSentences(e) for e in x] #The number of words containing both numeric and alphabetical characters. \n",
    "f4 = [numberSpam(e,spam) for e in x] # The number of words in an email that are found in the spam list.\n",
    "f5 = [moreThanThree(e) for e in x]  # The number of words in an email that have more than 3 syllables. \n",
    "f6 = [averageSyllables(e) for e in x]  # The average number of syllables of words in an email. \n",
    "\n",
    "feat_matrix = [[f1[i], f2[i], f3[i],f4[i],f5[i],f6[i]] for i in range(len(x))]\n",
    "print(len(feat_matrix))\n",
    "print(len(feat_matrix[1]))\n",
    "##FOR TESTING, N.B every function tested and working\n",
    "##par  = \"run, kick or push the wall, This is a parag2raph  So1 it is! Ok, there are 3 sentences. ability\"\n",
    "##averageSyllables(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of featureTrainMatrix 2314\n",
      "length of featureTestMatrix 579\n"
     ]
    }
   ],
   "source": [
    "dividing = int(len(feat_matrix) *0.8)\n",
    "feat_train = feat_matrix[:dividing]\n",
    "feat_test = feat_matrix[dividing:]\n",
    "print('length of featureTrainMatrix' , len(feat_train))\n",
    "print('length of featureTestMatrix' , len(feat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.310880829 %\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.84      0.94      0.89       486\n",
      "       spam       0.23      0.10      0.14        93\n",
      "\n",
      "avg / total       0.75      0.80      0.77       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feeding the feature matrix and labels to NaiveBayes\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "MNB.fit(feat_train, y_train)\n",
    "predMNB = MNB.predict(feat_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,predMNB) *100 , '%')\n",
    "print(metrics.classification_report(y_test, predMNB,target_names=email.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.3471502591 %\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.84      0.96      0.90       486\n",
      "       spam       0.20      0.05      0.08        93\n",
      "\n",
      "avg / total       0.74      0.81      0.77       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feeding the feature matrix and labels to KNeighbour\n",
    "neigh = KNeighborsClassifier()\n",
    "\n",
    "neigh.fit(feat_train, y_train)\n",
    "predNeigh = neigh.predict(feat_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,predNeigh) *100 , '%')\n",
    "print(metrics.classification_report(y_test, predNeigh,target_names=email.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.6925734024 %\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.84      0.97      0.90       486\n",
      "       spam       0.07      0.01      0.02        93\n",
      "\n",
      "avg / total       0.71      0.82      0.76       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feeding the feature matrix and labels to RandomForest\n",
    "RFC = RandomForestClassifier(random_state=0)\n",
    "\n",
    "RFC.fit(feat_train, y_train)\n",
    "predRFC = RFC.predict(feat_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,predRFC) *100 , '%')\n",
    "print(metrics.classification_report(y_test, predRFC,target_names=email.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
